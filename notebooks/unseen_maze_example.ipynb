{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-19T14:29:02.673517Z",
     "start_time": "2024-11-19T14:28:54.962568Z"
    }
   },
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib import animation\n",
    "from collections import deque, defaultdict, Counter\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "\n",
    "# ============ PARAMETER ============ #\n",
    "MAZE_FILE_PATH = \"./test_data/test2_15.json\"\n",
    "MAZE_SIZE = (10, 5)\n",
    "NUM_AGENTS = 2\n",
    "STARTING_POSITION = (0.5, 0.5)\n",
    "GOAL_POSITION = (9.5, 4.5)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "HIDDEN_SIZE = 24\n",
    "\n",
    "TRAINING_EPISODES = 20\n",
    "LEARNING_RATE = 0.05\n",
    "GAMMA = 0.995\n",
    "EPSILON_DECAY = 0.85\n",
    "MIN_EPSILON = 0.05\n",
    "SEQUENCE_LENGTH = 4\n",
    "MAX_STEPS_PER_EPISODE = 1000\n",
    "\n",
    "REWARD_GOAL = 100000             \n",
    "REWARD_NEW_POSITION = 100\n",
    "\n",
    "PENALTY_REVISIT = -5\n",
    "PENALTY_WALL_COLLISION = -100\n",
    "PENALTY_REPETITIVE_ACTION = -100\n",
    "PENALTY_FAILED_ACTION = -100\n",
    "\n",
    "MAX_REPETITIVE_ACTIONS = 2  \n",
    "DECAYING_REVISIT_FACTOR = 3 \n",
    "BACKTRACK_HISTORY_LENGTH = 2 \n",
    "PROXIMITY_REWARD_FACTOR = 0\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============ ENVIRONMENT LOADING ============ #\n",
    "def load_mazes_from_json(filepath):\n",
    "    \"\"\"Load maze data from a JSON file.\"\"\"\n",
    "    with open(filepath, \"r\") as file:\n",
    "        mazes = json.load(file)\n",
    "    return mazes\n",
    "\n",
    "# ============ ENVIRONMENT CLASS ============ #\n",
    "class MazeEnv:\n",
    "    def __init__(self, maze_data, starting_position=STARTING_POSITION, goal_position=GOAL_POSITION):\n",
    "        self.width = maze_data.get(\"width\", MAZE_SIZE[0])\n",
    "        self.height = maze_data.get(\"height\", MAZE_SIZE[1])\n",
    "        self.start_position = starting_position\n",
    "        self.goal_position = goal_position\n",
    "        self.walls = [frozenset({tuple(wall[\"start_position\"]), tuple(wall[\"end_position\"])}) for wall in maze_data[\"walls\"]]\n",
    "        self.walls_sorted_by_x, self.walls_sorted_by_y = self.preprocess_walls(self.walls)\n",
    "        self.failed_actions = defaultdict(set)  # Track failed actions at each cell\n",
    "        self.reset()\n",
    "\n",
    "    def preprocess_walls(self, walls):\n",
    "        \"\"\"Sort walls by coordinates for optimized wall detection.\"\"\"\n",
    "        walls_as_tuples = [tuple(sorted(wall)) for wall in walls]\n",
    "        walls_sorted_by_x = sorted(walls_as_tuples, key=lambda wall: (min(wall[0][0], wall[1][0]), min(wall[0][1], wall[1][1])))\n",
    "        walls_sorted_by_y = sorted(walls_as_tuples, key=lambda wall: (min(wall[0][1], wall[1][1]), min(wall[0][0], wall[1][0])))\n",
    "        return walls_sorted_by_x, walls_sorted_by_y\n",
    "\n",
    "    def reset(self):\n",
    "        \"\"\"Reset environment to the starting position and initialize visited positions and recent history.\"\"\"\n",
    "        self.position = self.start_position\n",
    "        self.done = False\n",
    "        self.visited_positions = {self.position}  # Track visited positions\n",
    "        self.recent_positions = deque(maxlen=BACKTRACK_HISTORY_LENGTH)  # Track recent positions\n",
    "        self.failed_actions.clear()  # Clear failed actions tracking\n",
    "        self.recent_positions.append(self.position)\n",
    "        return self.position\n",
    "    \n",
    "    def hits_wall(self, position, new_position):\n",
    "        \"\"\"Check if a movement would hit a wall, using sorted lists of walls for faster searching.\"\"\"\n",
    "        x, y = position\n",
    "        nx, ny = new_position\n",
    "        curr_x, curr_y = int(x), int(y)\n",
    "        next_x, next_y = int(nx), int(ny)\n",
    "\n",
    "        movement_direction = (\n",
    "            \"north\" if ny > y else \"south\" if ny < y else \"east\" if nx > x else \"west\"\n",
    "        ) if nx != x or ny != y else None\n",
    "\n",
    "        if not movement_direction:\n",
    "            return False  # No movement\n",
    "\n",
    "        relevant_walls = self.walls_sorted_by_y if movement_direction in [\"north\", \"south\"] else self.walls_sorted_by_x\n",
    "        for wall in relevant_walls:\n",
    "            (wx1, wy1), (wx2, wy2) = sorted(wall)\n",
    "            if movement_direction == \"north\" and wy1 == curr_y + 1 and wx1 <= curr_x < wx2:\n",
    "                return True\n",
    "            elif movement_direction == \"south\" and wy1 == curr_y and wx1 <= curr_x < wx2:\n",
    "                return True\n",
    "            elif movement_direction == \"east\" and wx1 == curr_x + 1 and wy1 <= curr_y < wy2:\n",
    "                return True\n",
    "            elif movement_direction == \"west\" and wx1 == curr_x and wy1 <= curr_y < wy2:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def proximity_reward(self, position):\n",
    "        \"\"\"Calculate proximity reward based on distance to the goal.\"\"\"\n",
    "        distance = math.sqrt((position[0] - self.goal_position[0]) ** 2 + (position[1] - self.goal_position[1]) ** 2)\n",
    "        return PROXIMITY_REWARD_FACTOR * (1 / (1 + distance))\n",
    "\n",
    "    def is_valid_position(self, position):\n",
    "        \"\"\"Ensure the position is within maze boundaries.\"\"\"\n",
    "        x, y = position\n",
    "        return 0 <= x < self.width and 0 <= y < self.height\n",
    "\n",
    "    def step(self, action):\n",
    "        \"\"\"Move the agent based on action and return position, reward, and completion status.\"\"\"\n",
    "        moves = [(-1, 0), (1, 0), (0, -1), (0, 1)]  # up, down, left, right\n",
    "        action_names = [\"North\", \"South\", \"West\", \"East\"]\n",
    "        dx, dy = moves[action]\n",
    "        new_position = (self.position[0] + dx, self.position[1] + dy)\n",
    "\n",
    "        reward = 0\n",
    "\n",
    "        # Check for wall collision\n",
    "        if self.is_valid_position(new_position) and not self.hits_wall(self.position, new_position):\n",
    "            self.position = new_position\n",
    "        else:\n",
    "            reward += PENALTY_WALL_COLLISION  # Penalty for attempting to go through a wall\n",
    "            self.failed_actions[self.position].add(action)  # Record failed action\n",
    "\n",
    "        # Determine reward based on outcome of the move\n",
    "        if self.position == self.goal_position:\n",
    "            reward += REWARD_GOAL\n",
    "            self.done = True\n",
    "\n",
    "        if self.position in self.visited_positions:\n",
    "            reward += PENALTY_REVISIT  # Penalty for revisiting\n",
    "\n",
    "        if action == self.failed_actions[self.position]:\n",
    "            reward += PENALTY_FAILED_ACTION \n",
    "        else:\n",
    "            reward += REWARD_NEW_POSITION  # Reward for new position\n",
    "            self.visited_positions.add(self.position)\n",
    "\n",
    "        # Add proximity reward based on closeness to the goal\n",
    "        reward += self.proximity_reward(self.position)\n",
    "\n",
    "        # Update recent positions\n",
    "        self.recent_positions.append(self.position)\n",
    "        return self.position, reward, self.done, action_names[action]\n",
    "\n",
    "# ============ VISUALIZATION ============ #\n",
    "def visualize_agent_run(env, positions, total_reward, total_steps):\n",
    "    # Prepare the figure and axis\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    cm_to_units = 1 / 2.54  # Conversion from cm to inches\n",
    "    margin = 1 * cm_to_units  # 1cm margin\n",
    "\n",
    "    ax.set_xlim(-margin, env.width + margin)\n",
    "    ax.set_ylim(-margin, env.height + margin)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    # Draw static elements (walls, start, goal)\n",
    "    for wall in env.walls:\n",
    "        (x1, y1), (x2, y2) = wall\n",
    "        ax.plot([x1, x2], [y1, y2], 'k', linewidth=3)  # Thicker walls\n",
    "\n",
    "    ax.plot(env.start_position[0], env.start_position[1], 'go', markersize=10, label=\"Start\")\n",
    "    ax.plot(env.goal_position[0], env.goal_position[1], 'ro', markersize=10, label=\"Goal\")\n",
    "\n",
    "    # Draw the heatmap-style path\n",
    "    position_counts = Counter(positions)\n",
    "    max_visits = max(position_counts.values())\n",
    "    colors = [\"lightblue\", \"blue\", \"darkblue\"]\n",
    "    cmap = mcolors.LinearSegmentedColormap.from_list(\"gradient\", colors)\n",
    "    norm = mcolors.Normalize(vmin=1, vmax=max_visits)\n",
    "\n",
    "    for i in range(len(positions) - 1):\n",
    "        x_values = [positions[i][0], positions[i + 1][0]]\n",
    "        y_values = [positions[i][1], positions[i + 1][1]]\n",
    "        color = cmap(norm(position_counts[positions[i + 1]]))\n",
    "        ax.plot(x_values, y_values, color=color, linewidth=2)\n",
    "\n",
    "    # Initialize the agent's position as a blue dot\n",
    "    agent_dot, = ax.plot([], [], 'bo', markersize=8, label=\"Agent\")\n",
    "\n",
    "    # Animation update function\n",
    "    def update(frame):\n",
    "        agent_dot.set_data([positions[frame][0]], [positions[frame][1]])\n",
    "        return agent_dot,\n",
    "\n",
    "    # Create animation\n",
    "    ani = animation.FuncAnimation(fig, update, frames=len(positions), interval=100, blit=True)\n",
    "\n",
    "    # Remove gridlines and axis labels\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Add legend and performance stats\n",
    "    ax.legend(loc=\"upper left\", fontsize=8)\n",
    "    ax.text(0.5, -1.5, f\"Steps: {total_steps}, Reward: {total_reward}\", fontsize=10, transform=ax.transAxes)\n",
    "\n",
    "    # Show the animation\n",
    "    plt.show()\n",
    "\n",
    "# ============ DEEP Q-NETWORK CLASS ============ #\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size=HIDDEN_SIZE):\n",
    "        super(DQN, self).__init__()\n",
    "        self.lstm = nn.LSTM(state_size, hidden_size, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, 24)\n",
    "        self.fc2 = nn.Linear(24, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"Perform a forward pass through the DQN.\"\"\"\n",
    "        h0 = torch.zeros(1, x.size(0), HIDDEN_SIZE).to(device)\n",
    "        c0 = torch.zeros(1, x.size(0), HIDDEN_SIZE).to(device)\n",
    "        x, _ = self.lstm(x, (h0, c0))\n",
    "        x = torch.relu(self.fc1(x[:, -1, :]))\n",
    "        return self.fc2(x)\n",
    "\n",
    "# ============ AGENT CLASS ============ #\n",
    "class Agent:\n",
    "    def __init__(self, state_size, action_size):\n",
    "        self.action_size = action_size\n",
    "        self.epsilon = 1.0\n",
    "        self.memory = deque(maxlen=2000)\n",
    "        self.model = DQN(state_size, action_size).to(device)\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=LEARNING_RATE)\n",
    "        self.loss_fn = nn.MSELoss()\n",
    "\n",
    "    def store_experience(self, state_seq, action, reward, next_state_seq, done):\n",
    "        \"\"\"Store experiences in memory for training.\"\"\"\n",
    "        self.memory.append((state_seq, action, reward, next_state_seq, done))\n",
    "\n",
    "    def act(self, state_seq, env):\n",
    "        \"\"\"Choose action based on epsilon-greedy policy, avoiding previously failed actions.\"\"\"\n",
    "        if random.random() <= self.epsilon:\n",
    "            available_actions = [a for a in range(self.action_size)]\n",
    "            if not available_actions:  # If all actions failed, allow any\n",
    "                available_actions = list(range(self.action_size))\n",
    "            return random.choice(available_actions)\n",
    "        \n",
    "        state_seq = torch.FloatTensor(state_seq).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            best_action = torch.argmax(self.model(state_seq)).item()\n",
    "        return best_action\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"Train model on randomly sampled experiences from memory.\"\"\"\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        minibatch = random.sample(self.memory, BATCH_SIZE)\n",
    "        for state_seq, action, reward, next_state_seq, done in minibatch:\n",
    "            state_seq = torch.FloatTensor(state_seq).unsqueeze(0).to(device)\n",
    "            next_state_seq = torch.FloatTensor(next_state_seq).unsqueeze(0).to(device)\n",
    "            target = reward + GAMMA * torch.max(self.model(next_state_seq)).item() * (1 - done)\n",
    "            target_f = self.model(state_seq).squeeze()\n",
    "            target_f[action] = target\n",
    "            loss = self.loss_fn(self.model(state_seq).squeeze(), target_f)\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "        if self.epsilon > MIN_EPSILON:\n",
    "            self.epsilon *= EPSILON_DECAY\n",
    "\n",
    "    def clone_from(self, best_agent):\n",
    "        \"\"\"Copy the model and optimizer state from the best agent.\"\"\"\n",
    "        self.model.load_state_dict(best_agent.model.state_dict())\n",
    "        self.optimizer.load_state_dict(best_agent.optimizer.state_dict())\n",
    "        self.epsilon = best_agent.epsilon\n",
    "\n",
    "# ============ TRAINING AND TESTING FUNCTIONS ============ #\n",
    "def train_agents_on_maze(agents, maze_data, training_repeats=10):\n",
    "    \"\"\"Train agents on a single maze and clone the best-performing agent.\"\"\"\n",
    "    best_agent = None\n",
    "    highest_reward = float('-inf')\n",
    "    for i, agent in enumerate(agents):\n",
    "        total_reward = 0\n",
    "        env = MazeEnv(maze_data)\n",
    "        state_seq = [env.reset()] * SEQUENCE_LENGTH\n",
    "        for step in range(MAX_STEPS_PER_EPISODE):\n",
    "            action = agent.act(state_seq, env)\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            next_state_seq = state_seq[1:] + [next_state]\n",
    "            agent.store_experience(state_seq, action, reward, next_state_seq, done)\n",
    "            state_seq = next_state_seq\n",
    "            total_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "        agent.replay()\n",
    "        print(f\"Agent {i + 1} completed training on maze with total reward: {total_reward}\")\n",
    "        if total_reward > highest_reward:\n",
    "            highest_reward = total_reward\n",
    "            best_agent = agent\n",
    "    print(f\"Best agent selected with reward: {highest_reward}\")\n",
    "    return best_agent\n",
    "\n",
    "def train_agents_across_mazes(agents, mazes):\n",
    "    \"\"\"Train agents across multiple mazes.\"\"\"\n",
    "    for maze_index, maze_data in enumerate(mazes):\n",
    "        print(f\"\\nTraining agents on maze {maze_index + 1}...\")\n",
    "        best_agent = train_agents_on_maze(agents, maze_data)\n",
    "        for agent in agents:\n",
    "            agent.clone_from(best_agent)\n",
    "\n",
    "def test_agent(agent, test_maze):\n",
    "    \"\"\"Test the trained agent on an unseen maze and render the path step-by-step.\"\"\"\n",
    "    env = MazeEnv(test_maze)\n",
    "    state_seq = [env.reset()] * SEQUENCE_LENGTH\n",
    "    path = [env.position]  # Start tracking the path from the initial position\n",
    "\n",
    "    total_reward = 0  # Track total reward during testing\n",
    "    positions = [env.position]  # List to store positions for animation\n",
    "\n",
    "    print(\"Agent's movements on the test maze:\")\n",
    "    for step in range(MAX_STEPS_PER_EPISODE):\n",
    "        action = agent.act(state_seq, env)\n",
    "        next_state, reward, done, action_name = env.step(action)\n",
    "        state_seq = state_seq[1:] + [next_state]\n",
    "        path.append(next_state)  # Track the new position\n",
    "        positions.append(next_state)  # Append to positions for animation\n",
    "        total_reward += reward  # Update total reward\n",
    "\n",
    "        # Print the current position, action, reward, and whether the goal was reached\n",
    "        print(f\"Step {step + 1}: Position {next_state}, Action {action_name}, Reward {reward}, Goal Reached: {done}\")\n",
    "\n",
    "        if done:\n",
    "            print(f\"Goal reached in {step + 1} steps.\")\n",
    "            break\n",
    "    else:\n",
    "        print(\"Did not reach the goal within the maximum steps.\")\n",
    "    \n",
    "    # Visualize the agent's movements step-by-step\n",
    "    visualize_agent_run(env, positions, total_reward, len(positions) - 1)\n",
    "\n",
    "# ============ MAIN SCRIPT ============ #\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Load mazes and split into training and testing sets\n",
    "ALL_MAZES = load_mazes_from_json(MAZE_FILE_PATH)\n",
    "TRAINING_MAZES = ALL_MAZES[:-1]\n",
    "TEST_MAZE = ALL_MAZES[-1]\n",
    "\n",
    "# Initialize multiple agents\n",
    "agents = [Agent(state_size=2, action_size=4) for _ in range(NUM_AGENTS)]\n",
    "\n",
    "# Train across mazes\n",
    "print(\"Training agents across mazes...\")\n",
    "train_agents_across_mazes(agents, TRAINING_MAZES)\n",
    "\n",
    "# Test the best agent from the last maze training\n",
    "best_agent = agents[0]  # Any agent, as they are all cloned to the best one at the end\n",
    "print(\"\\nTesting the best agent on unseen test maze...\")\n",
    "test_agent(best_agent, TEST_MAZE)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training agents across mazes...ERROR! Session/line number was not unique in database. History logging moved to new session 102\n",
      "\n",
      "\n",
      "Training agents on maze 1...\n",
      "Agent 1 completed training on maze with total reward: 50895.0\n",
      "Agent 2 completed training on maze with total reward: 47885.0\n",
      "Best agent selected with reward: 50895.0\n",
      "\n",
      "Training agents on maze 2...\n",
      "Agent 1 completed training on maze with total reward: 43215.0\n",
      "Agent 2 completed training on maze with total reward: 38510.0\n",
      "Best agent selected with reward: 43215.0\n",
      "\n",
      "Training agents on maze 3...\n",
      "Agent 1 completed training on maze with total reward: 39025.0\n",
      "Agent 2 completed training on maze with total reward: 33805.0\n",
      "Best agent selected with reward: 39025.0\n",
      "\n",
      "Training agents on maze 4...\n",
      "Agent 1 completed training on maze with total reward: 24945.0\n",
      "Agent 2 completed training on maze with total reward: 26445.0\n",
      "Best agent selected with reward: 26445.0\n",
      "\n",
      "Training agents on maze 5...\n",
      "Agent 1 completed training on maze with total reward: 30865.0\n",
      "Agent 2 completed training on maze with total reward: 30265.0\n",
      "Best agent selected with reward: 30865.0\n",
      "\n",
      "Training agents on maze 6...\n",
      "Agent 1 completed training on maze with total reward: 20235.0\n",
      "Agent 2 completed training on maze with total reward: 20245.0\n",
      "Best agent selected with reward: 20245.0\n",
      "\n",
      "Training agents on maze 7...\n",
      "Agent 1 completed training on maze with total reward: 15035.0\n",
      "Agent 2 completed training on maze with total reward: 16955.0\n",
      "Best agent selected with reward: 16955.0\n",
      "\n",
      "Training agents on maze 8...\n",
      "Agent 1 completed training on maze with total reward: 21230.0\n",
      "Agent 2 completed training on maze with total reward: 18525.0\n",
      "Best agent selected with reward: 21230.0\n",
      "\n",
      "Training agents on maze 9...\n",
      "Agent 1 completed training on maze with total reward: 13485.0\n",
      "Agent 2 completed training on maze with total reward: 13585.0\n",
      "Best agent selected with reward: 13585.0\n",
      "\n",
      "Training agents on maze 10...\n",
      "Agent 1 completed training on maze with total reward: 11265.0\n",
      "Agent 2 completed training on maze with total reward: 11875.0\n",
      "Best agent selected with reward: 11875.0\n",
      "\n",
      "Training agents on maze 11...\n",
      "Agent 1 completed training on maze with total reward: 4915.0\n",
      "Agent 2 completed training on maze with total reward: 4815.0\n",
      "Best agent selected with reward: 4915.0\n",
      "\n",
      "Training agents on maze 12...\n",
      "Agent 1 completed training on maze with total reward: 2015.0\n",
      "Agent 2 completed training on maze with total reward: 3620.0\n",
      "Best agent selected with reward: 3620.0\n",
      "\n",
      "Training agents on maze 13...\n",
      "Agent 1 completed training on maze with total reward: 101345.0\n",
      "Agent 2 completed training on maze with total reward: 101535.0\n",
      "Best agent selected with reward: 101535.0\n",
      "\n",
      "Training agents on maze 14...\n",
      "Agent 1 completed training on maze with total reward: 5750.0\n",
      "Agent 2 completed training on maze with total reward: 3255.0\n",
      "Best agent selected with reward: 5750.0\n",
      "\n",
      "Training agents on maze 15...\n",
      "Agent 1 completed training on maze with total reward: 101480.0\n",
      "Agent 2 completed training on maze with total reward: 101275.0\n",
      "Best agent selected with reward: 101480.0\n",
      "\n",
      "Testing the best agent on unseen test maze...\n",
      "Agent's movements on the test maze:\n",
      "Step 1: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 2: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 3: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 4: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 5: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 6: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 7: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 8: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 9: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 10: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 11: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 12: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 13: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 14: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 15: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 16: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 17: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 18: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 19: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 20: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 21: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 22: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 23: Position (1.5, 0.5), Action South, Reward 100.0, Goal Reached: False\n",
      "Step 24: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 25: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 26: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 27: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 28: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 29: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 30: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 31: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 32: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 33: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 34: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 35: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 36: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 37: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 38: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 39: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 40: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 41: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 42: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 43: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 44: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 45: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 46: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 47: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 48: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 49: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 50: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 51: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 52: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 53: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 54: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 55: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 56: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 57: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 58: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 59: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 60: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 61: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 62: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 63: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 64: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 65: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 66: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 67: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 68: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 69: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 70: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 71: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 72: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 73: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 74: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 75: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 76: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 77: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 78: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 79: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 80: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 81: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 82: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 83: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 84: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 85: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 86: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 87: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 88: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 89: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 90: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 91: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 92: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 93: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 94: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 95: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 96: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 97: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 98: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 99: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 100: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 101: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 102: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 103: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 104: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 105: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 106: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 107: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 108: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 109: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 110: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 111: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 112: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 113: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 114: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 115: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 116: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 117: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 118: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 119: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 120: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 121: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 122: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 123: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 124: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 125: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 126: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 127: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 128: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 129: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 130: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 131: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 132: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 133: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 134: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 135: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 136: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 137: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 138: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 139: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 140: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 141: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 142: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 143: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 144: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 145: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 146: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 147: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 148: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 149: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 150: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 151: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 152: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 153: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 154: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 155: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 156: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 157: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 158: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 159: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 160: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 161: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 162: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 163: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 164: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 165: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 166: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 167: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 168: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 169: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 170: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 171: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 172: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 173: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 174: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 175: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 176: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 177: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 178: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 179: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 180: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 181: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 182: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 183: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 184: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 185: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 186: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 187: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 188: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 189: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 190: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 191: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 192: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 193: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 194: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 195: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 196: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 197: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 198: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 199: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 200: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 201: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 202: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 203: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 204: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 205: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 206: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 207: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 208: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 209: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 210: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 211: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 212: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 213: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 214: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 215: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 216: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 217: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 218: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 219: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 220: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 221: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 222: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 223: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 224: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 225: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 226: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 227: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 228: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 229: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 230: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 231: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 232: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 233: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 234: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 235: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 236: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 237: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 238: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 239: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 240: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 241: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 242: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 243: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 244: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 245: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 246: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 247: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 248: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 249: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 250: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 251: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 252: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 253: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 254: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 255: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 256: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 257: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 258: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 259: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 260: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 261: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 262: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 263: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 264: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 265: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 266: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 267: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 268: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 269: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 270: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 271: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 272: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 273: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 274: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 275: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 276: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 277: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 278: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 279: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 280: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 281: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 282: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 283: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 284: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 285: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 286: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 287: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 288: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 289: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 290: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 291: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 292: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 293: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 294: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 295: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 296: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 297: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 298: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 299: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 300: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 301: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 302: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 303: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 304: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 305: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 306: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 307: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 308: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 309: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 310: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 311: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 312: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 313: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 314: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 315: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 316: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 317: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 318: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 319: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 320: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 321: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 322: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 323: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 324: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 325: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 326: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 327: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 328: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 329: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 330: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 331: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 332: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 333: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 334: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 335: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 336: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 337: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 338: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 339: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 340: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 341: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 342: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 343: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 344: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 345: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 346: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 347: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 348: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 349: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 350: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 351: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 352: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 353: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 354: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 355: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 356: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 357: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 358: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 359: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 360: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 361: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 362: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 363: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 364: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 365: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 366: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 367: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 368: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 369: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 370: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 371: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 372: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 373: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 374: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 375: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 376: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 377: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 378: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 379: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 380: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 381: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 382: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 383: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 384: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 385: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 386: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 387: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 388: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 389: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 390: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 391: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 392: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 393: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 394: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 395: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 396: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 397: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 398: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 399: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 400: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 401: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 402: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 403: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 404: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 405: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 406: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 407: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 408: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 409: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 410: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 411: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 412: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 413: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 414: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 415: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 416: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 417: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 418: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 419: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 420: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 421: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 422: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 423: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 424: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 425: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 426: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 427: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 428: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 429: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 430: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 431: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 432: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 433: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 434: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 435: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 436: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 437: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 438: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 439: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 440: Position (2.5, 0.5), Action South, Reward 100.0, Goal Reached: False\n",
      "Step 441: Position (1.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 442: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 443: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 444: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 445: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 446: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 447: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 448: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 449: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 450: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 451: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 452: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 453: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 454: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 455: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 456: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 457: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 458: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 459: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 460: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 461: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 462: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 463: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 464: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 465: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 466: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 467: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 468: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 469: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 470: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 471: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 472: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 473: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 474: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 475: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 476: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 477: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 478: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 479: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 480: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 481: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 482: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 483: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 484: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 485: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 486: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 487: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 488: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 489: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 490: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 491: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 492: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 493: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 494: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 495: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 496: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 497: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 498: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 499: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 500: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 501: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 502: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 503: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 504: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 505: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 506: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 507: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 508: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 509: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 510: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 511: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 512: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 513: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 514: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 515: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 516: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 517: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 518: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 519: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 520: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 521: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 522: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 523: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 524: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 525: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 526: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 527: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 528: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 529: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 530: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 531: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 532: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 533: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 534: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 535: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 536: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 537: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 538: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 539: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 540: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 541: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 542: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 543: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 544: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 545: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 546: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 547: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 548: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 549: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 550: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 551: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 552: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 553: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 554: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 555: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 556: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 557: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 558: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 559: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 560: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 561: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 562: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 563: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 564: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 565: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 566: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 567: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 568: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 569: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 570: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 571: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 572: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 573: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 574: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 575: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 576: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 577: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 578: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 579: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 580: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 581: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 582: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 583: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 584: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 585: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 586: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 587: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 588: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 589: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 590: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 591: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 592: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 593: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 594: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 595: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 596: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 597: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 598: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 599: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 600: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 601: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 602: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 603: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 604: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 605: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 606: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 607: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 608: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 609: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 610: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 611: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 612: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 613: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 614: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 615: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 616: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 617: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 618: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 619: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 620: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 621: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 622: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 623: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 624: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 625: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 626: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 627: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 628: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 629: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 630: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 631: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 632: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 633: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 634: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 635: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 636: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 637: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 638: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 639: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 640: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 641: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 642: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 643: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 644: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 645: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 646: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 647: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 648: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 649: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 650: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 651: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 652: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 653: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 654: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 655: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 656: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 657: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 658: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 659: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 660: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 661: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 662: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 663: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 664: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 665: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 666: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 667: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 668: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 669: Position (1.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 670: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 671: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 672: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 673: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 674: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 675: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 676: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 677: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 678: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 679: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 680: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 681: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 682: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 683: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 684: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 685: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 686: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 687: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 688: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 689: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 690: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 691: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 692: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 693: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 694: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 695: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 696: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 697: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 698: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 699: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 700: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 701: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 702: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 703: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 704: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 705: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 706: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 707: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 708: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 709: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 710: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 711: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 712: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 713: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 714: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 715: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 716: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 717: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 718: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 719: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 720: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 721: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 722: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 723: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 724: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 725: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 726: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 727: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 728: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 729: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 730: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 731: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 732: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 733: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 734: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 735: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 736: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 737: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 738: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 739: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 740: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 741: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 742: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 743: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 744: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 745: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 746: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 747: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 748: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 749: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 750: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 751: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 752: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 753: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 754: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 755: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 756: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 757: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 758: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 759: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 760: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 761: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 762: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 763: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 764: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 765: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 766: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 767: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 768: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 769: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 770: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 771: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 772: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 773: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 774: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 775: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 776: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 777: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 778: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 779: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 780: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 781: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 782: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 783: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 784: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 785: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 786: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 787: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 788: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 789: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 790: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 791: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 792: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 793: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 794: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 795: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 796: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 797: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 798: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 799: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 800: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 801: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 802: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 803: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 804: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 805: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 806: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 807: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 808: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 809: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 810: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 811: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 812: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 813: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 814: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 815: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 816: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 817: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 818: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 819: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 820: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 821: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 822: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 823: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 824: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 825: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 826: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 827: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 828: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 829: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 830: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 831: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 832: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 833: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 834: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 835: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 836: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 837: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 838: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 839: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 840: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 841: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 842: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 843: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 844: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 845: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 846: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 847: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 848: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 849: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 850: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 851: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 852: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 853: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 854: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 855: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 856: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 857: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 858: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 859: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 860: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 861: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 862: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 863: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 864: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 865: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 866: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 867: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 868: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 869: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 870: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 871: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 872: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 873: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 874: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 875: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 876: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 877: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 878: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 879: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 880: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 881: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 882: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 883: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 884: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 885: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 886: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 887: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 888: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 889: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 890: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 891: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 892: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 893: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 894: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 895: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 896: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 897: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 898: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 899: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 900: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 901: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 902: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 903: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 904: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 905: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 906: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 907: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 908: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 909: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 910: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 911: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 912: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 913: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 914: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 915: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 916: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 917: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 918: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 919: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 920: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 921: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 922: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 923: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 924: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 925: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 926: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 927: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 928: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 929: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 930: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 931: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 932: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 933: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 934: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 935: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 936: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 937: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 938: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 939: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 940: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 941: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 942: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 943: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 944: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 945: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 946: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 947: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 948: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 949: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 950: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 951: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 952: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 953: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 954: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 955: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 956: Position (0.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 957: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 958: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 959: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 960: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 961: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 962: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 963: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 964: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 965: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 966: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 967: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 968: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 969: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 970: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 971: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 972: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 973: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 974: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 975: Position (0.5, 0.5), Action West, Reward -5.0, Goal Reached: False\n",
      "Step 976: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 977: Position (1.5, 0.5), Action South, Reward 95.0, Goal Reached: False\n",
      "Step 978: Position (1.5, 0.5), Action East, Reward -5.0, Goal Reached: False\n",
      "Step 979: Position (0.5, 0.5), Action North, Reward 95.0, Goal Reached: False\n",
      "Step 980: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 981: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 982: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 983: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 984: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 985: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 986: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 987: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 988: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 989: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 990: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 991: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 992: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 993: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 994: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 995: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 996: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 997: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 998: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 999: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Step 1000: Position (0.5, 0.5), Action North, Reward -5.0, Goal Reached: False\n",
      "Did not reach the goal within the maximum steps.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": ""
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "WF-DataScience",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
